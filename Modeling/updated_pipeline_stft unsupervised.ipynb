{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3aa98a6",
   "metadata": {},
   "source": [
    "# Multimodal audio+image pipeline\n",
    "\n",
    "This notebook contains a reorganized, split version of the original monolithic pipeline.\n",
    "Cells are grouped by purpose (settings, extraction, audio cleaning, dataset, model, training, tests).\n",
    "Keep this structure for easier refactoring, commenting and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d7a2b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os, glob, subprocess\n",
    "\n",
    "import math, random\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch, torch.nn as nn, torch.nn.functional as F, torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from torchvision import transforms, models\n",
    "\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import torchaudio.functional as AF\n",
    "\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from collections import Counter\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score, davies_bouldin_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1ae34ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Helper Function: Extracts Audio ---\n",
    "def extract_audio_from_video(video_path, output_audio_dir, sr):\n",
    "    \"\"\"Uses FFmpeg to extract audio from video and save as a high-quality WAV.\"\"\"\n",
    "    # NOTE: Requires FFmpeg to be installed and in your system PATH.\n",
    "    os.makedirs(output_audio_dir, exist_ok=True)\n",
    "    video_filename = os.path.basename(video_path)\n",
    "    base_name = os.path.splitext(video_filename)[0]\n",
    "    output_wav_path = os.path.join(output_audio_dir, f\"{base_name}.wav\")\n",
    "    \n",
    "    # FFmpeg command: extract audio, set sample rate, convert to 16-bit PCM WAV\n",
    "    command = [\n",
    "        'ffmpeg',\n",
    "        '-i', video_path,\n",
    "        '-vn',  # No video\n",
    "        '-acodec', 'pcm_s16le', # Use 16-bit PCM for quality\n",
    "        '-ar', str(sr), # Set sample rate\n",
    "        output_wav_path,\n",
    "        '-y' # Overwrite if exists\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        # Suppress command line output for cleaner execution\n",
    "        subprocess.run(command, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "        return output_wav_path\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error extracting audio from {video_path}: {e}\")\n",
    "        return None\n",
    "    except FileNotFoundError:\n",
    "        print(\"ERROR: FFmpeg not found. Please ensure FFmpeg is installed and in your system PATH.\")\n",
    "        return None\n",
    "\n",
    "# --- Main Preparation Function: Creates Spectrograms ---\n",
    "# Place this at the top of your notebook if it's not already there\n",
    "import librosa # We need to make sure this is imported!\n",
    "\n",
    "# --- Main Preparation Function: Creates Spectrograms (FIXED VERSION) ---\n",
    "def prepare_dataset_from_videos(\n",
    "    raw_video_dir, audio_out_dir, spect_out_dir, sr, chunk_seconds,\n",
    "    clean_chunk_func # The function you already defined (clean_chunk)\n",
    "):\n",
    "    \"\"\"\n",
    "    Orchestrates the pipeline: Extracts audio, cleans, computes STFT, and saves as .npy.\n",
    "    \"\"\"\n",
    "    \n",
    "    os.makedirs(spect_out_dir, exist_ok=True)\n",
    "    video_files = glob.glob(os.path.join(raw_video_dir, \"*.mp4\")) + \\\n",
    "                  glob.glob(os.path.join(raw_video_dir, \"*.mov\")) \n",
    "    \n",
    "    if not video_files:\n",
    "        print(f\"[ERROR] No video files found in {raw_video_dir}. Check the path/extension.\")\n",
    "        return\n",
    "\n",
    "    # Helper STFT function (assumes NFFT/HOP are globally defined)\n",
    "    def _final_stft(x: torch.Tensor) -> torch.Tensor:\n",
    "        if x.dim() == 2: x = x.squeeze(0)\n",
    "        return torch.stft(x, n_fft=NFFT, hop_length=HOP, win_length=NFFT,\n",
    "                          window=torch.hann_window(NFFT), return_complex=True, center=True)\n",
    "\n",
    "    for video_path in tqdm(video_files, desc=\"Processing Videos\"):\n",
    "        base_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "        \n",
    "        # 1. Extract Audio (This part worked, but we keep it)\n",
    "        audio_path = extract_audio_from_video(video_path, audio_out_dir, sr)\n",
    "        if not audio_path: continue\n",
    "        \n",
    "        # 2. Load and Chunk Audio --- FIX IS HERE ---\n",
    "        try:\n",
    "            # FIX: Use librosa to load the audio file (more robust)\n",
    "            waveform_np, sr_loaded = librosa.load(audio_path, sr=sr, mono=True)\n",
    "            \n",
    "            # Convert NumPy array back to PyTorch Tensor for subsequent processing\n",
    "            waveform = torch.from_numpy(waveform_np).unsqueeze(0).to(torch.float32)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading audio {audio_path} with librosa: {e}\")\n",
    "            continue\n",
    "            \n",
    "        total_frames = waveform.shape[-1]\n",
    "        chunk_frames = sr * chunk_seconds\n",
    "        num_chunks = math.floor(total_frames / chunk_frames)\n",
    "\n",
    "        for i in range(num_chunks):\n",
    "            start_frame = i * chunk_frames\n",
    "            end_frame = start_frame + chunk_frames\n",
    "            chunk = waveform[:, start_frame:end_frame]\n",
    "            \n",
    "            # 3. Clean Chunk, Compute Spectrogram, and Save\n",
    "            try:\n",
    "                y_clean = clean_chunk_func(chunk, sr)\n",
    "                \n",
    "                S_complex = _final_stft(y_clean.squeeze(0))\n",
    "                S_mag = S_complex.abs()\n",
    "                \n",
    "                S_npy = S_mag.numpy().astype(np.float32)\n",
    "\n",
    "                spect_filename = f\"{base_name}_seg{i}.npy\"\n",
    "                spect_path = os.path.join(spect_out_dir, spect_filename)\n",
    "                np.save(spect_path, S_npy)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing chunk {i} of {base_name}: {e}\")\n",
    "                \n",
    "    print(f\"\\n--- SUCCESS ---\")\n",
    "    print(f\"Spectrograms saved to: {spect_out_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9575c486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch CUDA available: False\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "RAW_VIDEOS   = \"D:/Downloads/audio/full clips\"     # input videos\n",
    "AUDIO_DIR    = \"D:/Downloads/audio/aud\"   # output 2s wavs\n",
    "SPECT_DIR    = \"D:/Downloads/audio/spec\"  # output fft spec arrays\n",
    "\n",
    "SAMPLE_RATE  = 48000\n",
    "CHUNK_SECONDS= 2\n",
    "BATCH_SIZE   = 64\n",
    "EPOCHS       = 7\n",
    "DEVICE       = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Print device info to confirm CUDA availability and details\n",
    "print('Torch CUDA available:', torch.cuda.is_available())\n",
    "print('Using device:', DEVICE)\n",
    "if torch.cuda.is_available():\n",
    "    try:\n",
    "        print('CUDA device count:', torch.cuda.device_count())\n",
    "        if torch.cuda.device_count() > 0:\n",
    "            try:\n",
    "                cur = torch.cuda.current_device()\n",
    "                print('CUDA current device index:', cur)\n",
    "                print('CUDA device name:', torch.cuda.get_device_name(cur))\n",
    "            except Exception as e:\n",
    "                print('Could not query CUDA device name:', e)\n",
    "    except Exception as e:\n",
    "        print('CUDA query error:', e)\n",
    "\n",
    "label_map = {\"0p_10m\": 0, \"50p_10m\": 1, \"100p_10m\": 2}\n",
    "LABELS = {v: k.capitalize() for k, v in label_map.items()}\n",
    "\n",
    "os.makedirs(AUDIO_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "810fc8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "import torch.nn.functional as F\n",
    "from scipy.signal import butter, lfilter\n",
    "from typing import Tuple\n",
    "\n",
    "# --- GLOBAL CONSTANTS (Assuming these are defined correctly elsewhere, but included for completeness) ---\n",
    "# If these variables are not defined globally, you must define them here:\n",
    "# SAMPLE_RATE, NFFT, HOP, etc.\n",
    "# Example:\n",
    "# SAMPLE_RATE = 44100 \n",
    "# NFFT = 2048 \n",
    "# HOP = 512 \n",
    "\n",
    "SR        = SAMPLE_RATE\n",
    "BAND_LO   = 12000\n",
    "BAND_HI   = 18000\n",
    "NFFT      = 2048\n",
    "HOP       = 512\n",
    "OVERSUB   = 1.2\n",
    "QUIET_PCT = 0.20\n",
    "\n",
    "# 1. Bandpass Filter Helpers (Using Scipy for the actual filtering)\n",
    "def butter_bandpass(lowcut, highcut, sr, order=5):\n",
    "    \"\"\"Returns the coefficients for a digital Butterworth bandpass filter.\"\"\"\n",
    "    nyquist = 0.5 * sr\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def bandpass_chunk(waveform: torch.Tensor, sr: int) -> torch.Tensor:\n",
    "    \"\"\"Applies bandpass filtering using Scipy's lfilter.\"\"\"\n",
    "    # Convert PyTorch Tensor to NumPy array for Scipy filtering\n",
    "    y_np = waveform.squeeze().cpu().numpy()\n",
    "    \n",
    "    b, a = butter_bandpass(BAND_LO, BAND_HI, sr)\n",
    "    \n",
    "    # Apply filter using Scipy\n",
    "    y_filtered_np = lfilter(b, a, y_np)\n",
    "    \n",
    "    # Convert back to PyTorch Tensor\n",
    "    y_filtered = torch.from_numpy(y_filtered_np).to(waveform.device).float().unsqueeze(0)\n",
    "    return y_filtered\n",
    "\n",
    "\n",
    "# 2. STFT and ISTFT (Using PyTorch's native functions)\n",
    "def _stft(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Compute Short-Time Fourier Transform, returning a complex tensor.\"\"\"\n",
    "    if x.dim() == 2: x = x.squeeze(0)\n",
    "    # Ensure input is float32\n",
    "    x = x = x.to(torch.float32) \n",
    "    return torch.stft(x, n_fft=NFFT, hop_length=HOP, win_length=NFFT,\n",
    "                      window=torch.hann_window(NFFT, dtype=torch.float32, device=x.device), \n",
    "                      return_complex=True, center=True)\n",
    "\n",
    "def _istft(S_complex: torch.Tensor, length: int) -> torch.Tensor:\n",
    "    \"\"\"Compute Inverse STFT.\"\"\"\n",
    "    # ISTFT requires a window function\n",
    "    window = torch.hann_window(NFFT, dtype=torch.float32, device=S_complex.device)\n",
    "    \n",
    "    y = torch.istft(S_complex, n_fft=NFFT, hop_length=HOP, win_length=NFFT, \n",
    "                    window=window, return_complex=False, center=True, length=length)\n",
    "    return y.unsqueeze(0)\n",
    "\n",
    "\n",
    "# 3. spectral_subtract_quiet_frames\n",
    "def spectral_subtract_quiet_frames(waveform: torch.Tensor, sr: int) -> torch.Tensor:\n",
    "    \"\"\"Performs spectral subtraction based on quiet frames.\"\"\"\n",
    "    x = waveform.squeeze(0).to(torch.float32)\n",
    "    Tlen = x.shape[-1]\n",
    "    \n",
    "    # Compute STFT\n",
    "    S = _stft(x)\n",
    "    Mag = S.abs()\n",
    "    Pow = Mag**2\n",
    "    \n",
    "    # --- Noise Estimation ---\n",
    "    # Find power in the target band\n",
    "    freqs = np.fft.rfftfreq(NFFT, d=1.0/sr)\n",
    "    lo = int(np.searchsorted(freqs, BAND_LO))\n",
    "    hi = int(np.searchsorted(freqs, BAND_HI))\n",
    "    lo = max(lo, 0); hi = min(hi, Mag.shape[0])\n",
    "    \n",
    "    band_pow_per_frame = Pow[lo:hi].mean(dim=0)\n",
    "    T_frames = band_pow_per_frame.numel()\n",
    "    \n",
    "    # Identify the quietest frames (potential noise floor)\n",
    "    k = max(1, int(round(QUIET_PCT * T_frames)))\n",
    "    vals, idxs = torch.topk(-band_pow_per_frame, k)\n",
    "    quiet_mask = torch.zeros_like(band_pow_per_frame, dtype=torch.bool)\n",
    "    quiet_mask[idxs] = True\n",
    "    \n",
    "    # Estimate Noise Power Spectral Density (Npsd)\n",
    "    Npsd = Pow[:, quiet_mask].mean(dim=1, keepdim=True)\n",
    "    \n",
    "    # --- Subtraction ---\n",
    "    Pclean = torch.clamp(Pow - OVERSUB * Npsd, min=0.0)\n",
    "    Mag_clean = torch.sqrt(Pclean + 1e-12)\n",
    "    \n",
    "    # Combine clean magnitude with original phase\n",
    "    S_clean = Mag_clean * torch.exp(1j * S.angle())\n",
    "    \n",
    "    # Inverse STFT\n",
    "    y_clean = _istft(S_clean, length=Tlen)\n",
    "    \n",
    "    # Post-processing (DC removal and normalization)\n",
    "    y_clean = y_clean - y_clean.mean()\n",
    "    y_clean = torch.nan_to_num(y_clean, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    return y_clean.unsqueeze(0)\n",
    "\n",
    "\n",
    "# 4. clean_chunk (The main wrapper function)\n",
    "def clean_chunk(waveform: torch.Tensor, sr: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Applies the full audio cleaning pipeline: Resampling, Bandpass, and Spectral Subtraction.\n",
    "    \"\"\"\n",
    "    # Standardize input to (1, N) float32 tensor\n",
    "    if waveform.dim() == 2 and waveform.shape[0] > 1:\n",
    "        waveform = waveform.mean(dim=0, keepdim=True)\n",
    "    elif waveform.dim() == 1:\n",
    "        waveform = waveform.unsqueeze(0)\n",
    "        \n",
    "    waveform = waveform.to(torch.float32)\n",
    "    \n",
    "    # 1. Resample if necessary\n",
    "    if sr != SR:\n",
    "        # torchaudio.functional.resample handles device/dtype\n",
    "        waveform = torchaudio.functional.resample(waveform, sr, SR).to(torch.float32)\n",
    "        sr = SR\n",
    "        \n",
    "    # 2. Bandpass Filter (The definition that was missing)\n",
    "    y_bp = bandpass_chunk(waveform, sr)\n",
    "    \n",
    "    # 3. Spectral Subtraction\n",
    "    y_cl = spectral_subtract_quiet_frames(y_bp, sr)\n",
    "    \n",
    "    return y_cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b75a2c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Cell 50A: Contrastive Learning Augmentations\n",
    "\n",
    "# Simple Spectrogram Augmentation Functions\n",
    "# (Operating on a single-channel PyTorch tensor of shape (1, F, T))\n",
    "\n",
    "def freq_mask(spec: torch.Tensor, max_mask_pct=0.1):\n",
    "    \"\"\"Applies frequency masking.\"\"\"\n",
    "    F = spec.shape[-2]\n",
    "    max_mask_freq = int(F * max_mask_pct)\n",
    "    if max_mask_freq <= 0: return spec\n",
    "    \n",
    "    # Create a torchaudio FrequencyMasking transform\n",
    "    masking = T.FrequencyMasking(\n",
    "        freq_mask_param=max_mask_freq, \n",
    "        iid_masks=True  # Apply a new mask for each call\n",
    "    )\n",
    "    return masking(spec)\n",
    "\n",
    "def time_mask(spec: torch.Tensor, max_mask_pct=0.1):\n",
    "    \"\"\"Applies time masking.\"\"\"\n",
    "    T_frames = spec.shape[-1]\n",
    "    max_mask_time = int(T_frames * max_mask_pct)\n",
    "    if max_mask_time <= 0: return spec\n",
    "\n",
    "    # Create a torchaudio TimeMasking transform\n",
    "    masking = T.TimeMasking(\n",
    "        time_mask_param=max_mask_time,\n",
    "        iid_masks=True # Apply a new mask for each call\n",
    "    )\n",
    "    return masking(spec)\n",
    "\n",
    "def contrastive_augment(spec: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Combines masking operations for a single augmented view.\"\"\"\n",
    "    spec = freq_mask(spec)\n",
    "    spec = time_mask(spec)\n",
    "    return spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b73dcb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset \n",
    "import torch.nn.functional as F \n",
    "\n",
    "# Assuming contrastive_augment is defined elsewhere\n",
    "\n",
    "# --- CRITICAL FIX 1: DEFINE THE TRANSLATION MAP ---\n",
    "# This maps the short name from the filename (e.g., 'empty') to the long key \n",
    "# in your label_map (e.g., '0p_10m').\n",
    "# NOTE: We assume your filenames are empty, half, and full.\n",
    "FILENAME_TO_LABEL_KEY = {\n",
    "    'empty': '0p_10m',\n",
    "    'half': '50p_10m', \n",
    "    'full': '100p_10m'\n",
    "}\n",
    "# --------------------------------------------------\n",
    "\n",
    "class UnsupervisedAudioDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Final, robust dataset for self-supervised contrastive learning.\n",
    "    Now includes robust label translation.\n",
    "    \"\"\"\n",
    "    def __init__(self, spect_dir, label_map, all_files):\n",
    "        self.spect_dir = spect_dir\n",
    "        \n",
    "        # Standardize label_map keys to lowercase defensively\n",
    "        self.label_map = {k.lower(): v for k, v in label_map.items()}\n",
    "        \n",
    "        self.valid_files = [] \n",
    "        self.labels = []\n",
    "        self.seg_ids = []\n",
    "\n",
    "        # Robust File Parsing Loop\n",
    "        for file_path in all_files:\n",
    "            base_name = os.path.basename(file_path)\n",
    "            \n",
    "            # 1. Extract the raw state name (e.g., 'empty')\n",
    "            if '__' in base_name:\n",
    "                soc_state_raw = base_name.split('__')[0]\n",
    "            elif '_' in base_name:\n",
    "                soc_state_raw = base_name.split('_')[0]\n",
    "            else:\n",
    "                soc_state_raw = os.path.splitext(base_name)[0]\n",
    "\n",
    "            # 2. Convert to lowercase\n",
    "            soc_state_internal = soc_state_raw.lower()\n",
    "            \n",
    "            # 3. CRITICAL NEW STEP: Translate the short name to the long key\n",
    "            final_label_key = FILENAME_TO_LABEL_KEY.get(soc_state_internal, None)\n",
    "            \n",
    "            # 4. Check against the standardized label_map using the translated key\n",
    "            if final_label_key is not None and final_label_key in self.label_map:\n",
    "                # SUCCESS: Append to all three synchronized lists\n",
    "                self.valid_files.append(file_path) \n",
    "                self.labels.append(self.label_map[final_label_key]) # Use the long key!\n",
    "                self.seg_ids.append(base_name)\n",
    "            # ELSE: Skip the file (this is fine, the file is intentionally ignored if the translation fails)\n",
    "            \n",
    "        print(f\"Loaded {len(self.valid_files)} spectrograms from {spect_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.valid_files[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        S_ultra = np.load(path).astype(np.float32)\n",
    "\n",
    "        # Fix Time-Dimension Mismatch\n",
    "        target_W = 400\n",
    "        F, W = S_ultra.shape\n",
    "        if W < target_W:\n",
    "            pad = target_W - W\n",
    "            S_ultra = np.pad(S_ultra, ((0, 0), (0, pad)), mode='constant')\n",
    "        elif W > target_W:\n",
    "            S_ultra = S_ultra[:, :target_W]\n",
    "        \n",
    "        # Normalize\n",
    "        S_ultra = (S_ultra - S_ultra.mean()) / (S_ultra.std() + 1e-6)\n",
    "        \n",
    "        # To Tensor and unsqueeze for channel dim: shape (1, F, T)\n",
    "        audio_tensor = torch.tensor(S_ultra).unsqueeze(0)\n",
    "\n",
    "        # Apply two different augmentations \n",
    "        view_1 = contrastive_augment(audio_tensor.clone()) \n",
    "        view_2 = contrastive_augment(audio_tensor.clone())\n",
    "\n",
    "        return view_1, view_2, label, self.seg_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b60ffd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loaders(\n",
    "    dataset,\n",
    "    batch_size,\n",
    "    train_frac=0.70,\n",
    "    val_frac=0.20,\n",
    "    test_frac=0.1,\n",
    "    seed=42,\n",
    "):\n",
    "    assert abs(train_frac + val_frac + test_frac - 1.0) < 1e-6, \"Fractions must sum to 1.0\"\n",
    "\n",
    "    n = len(dataset)\n",
    "    indices = list(range(n))\n",
    "\n",
    "    random.seed(seed)\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    n_train = int(n * train_frac)\n",
    "    n_val   = int(n * val_frac)\n",
    "    n_test  = n - n_train - n_val\n",
    "\n",
    "    train_idx = indices[:n_train]\n",
    "    val_idx   = indices[n_train:n_train + n_val]\n",
    "    test_idx  = indices[n_train + n_val:]\n",
    "\n",
    "    train_ds = Subset(dataset, train_idx)\n",
    "    val_ds   = Subset(dataset, val_idx)\n",
    "    test_ds  = Subset(dataset, test_idx)\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Train samples: {len(train_ds)}, \"\n",
    "        f\"Val samples: {len(val_ds)}, \"\n",
    "        f\"Test samples: {len(test_ds)}\"\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "930ac41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified Cell 52: Define Contrastive Model Architecture\n",
    "\n",
    "class AudioFeatureExtractor(nn.Module):\n",
    "    \"\"\"\n",
    "    A ResNet backbone modified for single-channel spectrogram input.\n",
    "    The final fully connected layer is replaced with nn.Identity() to output\n",
    "    the 512-dimension feature vector (the embedding).\n",
    "    \"\"\"\n",
    "    def __init__(self, pretrained=True):\n",
    "        super().__init__()\n",
    "        # Use ResNet-18 as the backbone\n",
    "        self.backbone = models.resnet18(weights=\"IMAGENET1K_V1\" if pretrained else None)\n",
    "        \n",
    "        # 1. Adapt conv1 for 1-channel input (spectrogram)\n",
    "        self.backbone.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        \n",
    "        # 2. Use AdaptiveAvgPool to handle variable spectrogram width\n",
    "        self.backbone.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # 3. Replace the final linear layer with Identity to get the features\n",
    "        self.backbone.fc = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (B, 1, F, T)\n",
    "        return self.backbone(x) # Output shape: (B, 512)\n",
    "\n",
    "class ProjectionHead(nn.Module):\n",
    "    \"\"\"\n",
    "    The non-linear head g(z) used in SimCLR to project features\n",
    "    into the space where the contrastive loss is applied.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=512, hidden_dim=512, output_dim=128):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim, bias=False),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, output_dim, bias=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x) # Output shape: (B, 128)\n",
    "\n",
    "class ContrastiveModel(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = AudioFeatureExtractor(pretrained=pretrained)\n",
    "        self.projection_head = ProjectionHead()\n",
    "\n",
    "    def forward(self, x, return_embedding=False):\n",
    "        # x: augmented view (B, 1, F, T)\n",
    "        \n",
    "        # 1. Get the feature embedding (z)\n",
    "        z = self.feature_extractor(x)  # (B, 512)\n",
    "        \n",
    "        # 2. Project the feature (h)\n",
    "        h = self.projection_head(z)    # (B, 128)\n",
    "        \n",
    "        if return_embedding:\n",
    "            # We return the 512-dim embedding (z) for t-SNE visualization/clustering\n",
    "            return z, h\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31557e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Cell 54A: NT-Xent Loss Implementation\n",
    "\n",
    "class NTXentLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.5, device=DEVICE):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.device = device\n",
    "        self.criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "        self.similarity_f = nn.CosineSimilarity(dim=2)\n",
    "\n",
    "    def mask_diag(self, x):\n",
    "        # Removes self-similarity from the matrix (the main diagonal)\n",
    "        return x * (1 - torch.eye(x.shape[0], device=self.device))\n",
    "\n",
    "    def forward(self, z_i, z_j):\n",
    "        \"\"\"\n",
    "        Calculates the NT-Xent loss for two batches of projected features (z_i, z_j).\n",
    "        z_i and z_j are (B, P) where P is projection head output dim.\n",
    "        \"\"\"\n",
    "        # Concatenate all features (2N)\n",
    "        z = torch.cat((z_i, z_j), dim=0) # (2B, P)\n",
    "        \n",
    "        # Calculate pairwise cosine similarity\n",
    "        sim = self.similarity_f(z.unsqueeze(1), z.unsqueeze(0)) # (2B, 2B)\n",
    "        \n",
    "        # Mask out the diagonal (self-similarity)\n",
    "        sim_no_diag = self.mask_diag(sim)\n",
    "        \n",
    "        # Scale by temperature\n",
    "        sim_scaled = sim_no_diag / self.temperature\n",
    "\n",
    "        # Create labels: target is the positive pair (the other view of the same sample)\n",
    "        # N is the original batch size\n",
    "        N = z_i.shape[0]\n",
    "        \n",
    "        # Positive index for z_i: [N, N+1, ..., 2N-1]\n",
    "        p_i = torch.arange(N, 2*N, device=self.device)\n",
    "        \n",
    "        # Positive index for z_j: [0, 1, ..., N-1]\n",
    "        p_j = torch.arange(N, device=self.device)\n",
    "        \n",
    "        # Combine positive indices: [N, N+1, ..., 2N-1, 0, 1, ..., N-1]\n",
    "        positive_samples = torch.cat((p_i, p_j), dim=0)\n",
    "\n",
    "        # The contrastive loss is a form of CrossEntropyLoss\n",
    "        # Logits are the similarity values (sim_scaled)\n",
    "        # The target label for each row is the index of its positive pair (positive_samples)\n",
    "        \n",
    "        loss = self.criterion(sim_scaled, positive_samples)\n",
    "        \n",
    "        # The total loss is summed over the 2N samples and then averaged over the batch size N\n",
    "        return loss / (2 * N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7cb39ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified Cell 53: FEATURE VISUALIZATION (t-SNE)\n",
    "\n",
    "def visualize_features(model, dataloader, title_suffix=\"\"):\n",
    "    model.eval()\n",
    "    audio_feats, labels_all = [], []\n",
    "\n",
    "    # Check if the model is the ContrastiveModel\n",
    "    if isinstance(model, ContrastiveModel):\n",
    "        extractor = model.feature_extractor\n",
    "    else:\n",
    "        # If it's the old MultiModalResNet, we can still use the audio path\n",
    "        extractor = model.audio_model\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # The dataloader now returns (view_1, view_2, labels, seg_ids)\n",
    "            # or (audio, img, labels, seg_ids) if using the old dataset.\n",
    "            # We must handle both cases. Assume new dataset for unsupervised.\n",
    "            if len(batch) == 4 and isinstance(batch[0], torch.Tensor) and batch[0].dim() == 4:\n",
    "                # New Unsupervised Dataset: (view_1, view_2, labels, seg_ids)\n",
    "                view_1, _, labels, _ = batch\n",
    "                audio_input = view_1\n",
    "            else:\n",
    "                # Old Supervised Dataset: (audio, img, labels, seg_ids)\n",
    "                audio_input, _, labels, _ = batch\n",
    "            \n",
    "            audio_input, labels = audio_input.to(DEVICE), labels.to(DEVICE)\n",
    "            \n",
    "            # The feature extractor outputs the 512-dim embedding (z)\n",
    "            a = extractor(audio_input) \n",
    "            \n",
    "            audio_feats.append(a.cpu())\n",
    "            labels_all.append(labels.cpu())\n",
    "\n",
    "    if len(audio_feats) == 0:\n",
    "        print(\"[visualize_features] No samples in dataloader – skipping t-SNE.\")\n",
    "        return\n",
    "\n",
    "    audio_feats = torch.cat(audio_feats).numpy()\n",
    "    labels_all = torch.cat(labels_all).numpy()\n",
    "\n",
    "    print(\"Label counts:\", Counter(labels_all))\n",
    "\n",
    "    n = audio_feats.shape[0]\n",
    "    if n < 5: # Small change to allow for very small batches in test\n",
    "        print(f\"[visualize_features] Only {n} samples – too few for t-SNE. Skipping.\")\n",
    "        return\n",
    "\n",
    "    perpl = min(30, max(5, min(n - 1, n // 3)))\n",
    "\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=perpl)\n",
    "    A2 = tsne.fit_transform(audio_feats)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "    \n",
    "    # Plotting using the (unseen) true labels to evaluate clustering quality\n",
    "    for l in sorted(set(labels_all)):\n",
    "        idx = labels_all == l\n",
    "        ax.scatter(A2[idx, 0], A2[idx, 1], alpha=0.6, s=20, label=LABELS[l])\n",
    "        \n",
    "    ax.set_title(f\"Audio Features t-SNE {title_suffix}\")\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return audio_feats, labels_all # Returning features for potential clustering metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c721c0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "# Make sure ContrastiveModel, NTXentLoss, create_loaders, visualize_features, \n",
    "# and UnsupervisedAudioDataset are defined in other cells, but we assume them here.\n",
    "\n",
    "\n",
    "def train_unsupervised():\n",
    "    # --- 1. FILE GATHERING (FIXED for robustness) ---\n",
    "    import os, glob # Ensure glob and os are imported within function scope\n",
    "    \n",
    "    # Use os.path.normpath for maximum path robustness across systems\n",
    "    normalized_spect_dir = os.path.normpath(SPECT_DIR) \n",
    "    \n",
    "    # Search for all .npy files.\n",
    "    all_files = sorted(glob.glob(os.path.join(normalized_spect_dir, \"*.npy\")))\n",
    "    \n",
    "    print(f\"DEBUG: Successfully found {len(all_files)} spectrogram files.\")\n",
    "\n",
    "    if len(all_files) == 0:\n",
    "        print(f\"[FATAL ERROR] Dataset size is 0. Check SPECT_DIR path: {SPECT_DIR}\")\n",
    "        return None, None, None\n",
    "\n",
    "    # 2. Instantiate the new unsupervised dataset\n",
    "    # This now passes the file list directly to bypass buggy internal file-finding\n",
    "    dataset = UnsupervisedAudioDataset(\n",
    "        spect_dir=SPECT_DIR,\n",
    "        all_files=all_files, \n",
    "        label_map=label_map\n",
    "    )\n",
    "    \n",
    "    print(f\"DEBUG: FINAL dataset size is {len(dataset)}\") # Reconfirm size\n",
    "    \n",
    "    if len(dataset) < BATCH_SIZE * 2: # Contrastive loss needs a reasonable batch size\n",
    "        print(f\"[ERROR] Dataset size ({len(dataset)}) is too small for contrastive learning with batch size {BATCH_SIZE}.\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # 3. Create DataLoaders (assuming create_loaders is defined and works)\n",
    "    train_loader, val_loader, test_loader = create_loaders(dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "    # 4. Instantiate the Contrastive Model and Loss\n",
    "    model = ContrastiveModel(pretrained=True).to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    criterion = NTXentLoss(temperature=0.5, device=DEVICE) \n",
    "    \n",
    "    print(\"Visualizing features BEFORE training...\")\n",
    "    visualize_features(model, val_loader, title_suffix=\"(Before Contrastive Training)\")\n",
    "\n",
    "    for epoch in tqdm(range(EPOCHS)):\n",
    "        # ... (Training loop logic) ...\n",
    "        model.train()\n",
    "        running_loss, total = 0.0, 0\n",
    "\n",
    "        for view_1, view_2, labels, seg_ids in train_loader:\n",
    "            view_1 = view_1.to(DEVICE)\n",
    "            view_2 = view_2.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            h_i = model(view_1)\n",
    "            h_j = model(view_2)\n",
    "            loss = criterion(h_i, h_j)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_size = view_1.size(0)\n",
    "            running_loss += loss.item() * batch_size\n",
    "            total += batch_size\n",
    "        \n",
    "        # ... (Validation and printing logic) ...\n",
    "        train_loss = running_loss / max(1, total)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, val_total = 0.0, 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for view_1, view_2, labels, seg_ids in val_loader:\n",
    "                view_1 = view_1.to(DEVICE)\n",
    "                view_2 = view_2.to(DEVICE)\n",
    "                h_i = model(view_1)\n",
    "                h_j = model(view_2)\n",
    "                loss = criterion(h_i, h_j)\n",
    "\n",
    "                batch_size = view_1.size(0)\n",
    "                val_loss += loss.item() * batch_size\n",
    "                val_total += batch_size\n",
    "\n",
    "        val_loss /= max(1, val_total)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch [{epoch+1}/{EPOCHS}] \"\n",
    "            f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\"\n",
    "        )\n",
    "    \n",
    "    print(\"\\nVisualizing features AFTER training...\")\n",
    "    visualize_features(model, val_loader, title_suffix=\"(After Contrastive Training)\")\n",
    "    \n",
    "    return model, test_loader, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2a023e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test_unsupervised(model, dataloader):\n",
    "    \"\"\"\n",
    "    Quantitative evaluation of the unsupervised features.\n",
    "    1. Extracts embeddings (z).\n",
    "    2. Clusters them using K-Means (assuming 3 clusters as discussed).\n",
    "    3. Calculates Silhouette and ARI scores.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Running Unsupervised Quantitative Test ---\")\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for view_1, _, labels, _ in dataloader:\n",
    "            view_1 = view_1.to(DEVICE)\n",
    "            # Get the 512-dim embedding\n",
    "            z = model.feature_extractor(view_1)\n",
    "            embeddings.append(z.cpu())\n",
    "            true_labels.append(labels.cpu())\n",
    "\n",
    "    embeddings = torch.cat(embeddings).numpy()\n",
    "    true_labels = torch.cat(true_labels).numpy()\n",
    "    \n",
    "    # --- 1. Natural Clustering ---\n",
    "    # We tell K-Means to find 3 groups (the 3 states we expect)\n",
    "    num_clusters = 3 \n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)\n",
    "    cluster_preds = kmeans.fit_transform(embeddings)\n",
    "    cluster_labels = kmeans.labels_\n",
    "\n",
    "    # --- 2. Calculate Metrics ---\n",
    "    \n",
    "    # Silhouette Score: (1 is perfect separation, -1 is total overlap)\n",
    "    # Measures Path B Goal: Cluster Distinctness\n",
    "    sil_score = silhouette_score(embeddings, cluster_labels)\n",
    "    \n",
    "    # Davies-Bouldin Index: (Lower is better)\n",
    "    # Measures how tight the clusters are.\n",
    "    db_index = davies_bouldin_score(embeddings, cluster_labels)\n",
    "    \n",
    "    # Adjusted Rand Index (ARI): (1 is perfect match to our SOC labels)\n",
    "    # This measures if the clusters the model found match the SOC levels.\n",
    "    ari_score = adjusted_rand_score(true_labels, cluster_labels)\n",
    "\n",
    "    print(f\"Results for Path B:\")\n",
    "    print(f\"  - Silhouette Score (Separation): {sil_score:.4f}\")\n",
    "    print(f\"  - Davies-Bouldin Index (Tightness): {db_index:.4f}\")\n",
    "    print(f\"  - Match to SOC Labels (ARI): {ari_score:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"embeddings\": embeddings,\n",
    "        \"true_labels\": true_labels,\n",
    "        \"cluster_labels\": cluster_labels,\n",
    "        \"metrics\": {\"silhouette\": sil_score, \"ari\": ari_score, \"db\": db_index}\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74eaef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Glob found 270 files.\n",
      "First file found: D:/Downloads/audio/spec\\empty__seg0.npy\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# NOTE: The value of SPECT_DIR must be D:/Downloads/audio/spec\n",
    "# If SPECT_DIR is not defined, please replace it with the exact path string.\n",
    "try:\n",
    "    file_list = glob.glob(os.path.join(SPECT_DIR, \"*.npy\"))\n",
    "    print(f\"DEBUG: Glob found {len(file_list)} files.\")\n",
    "    if len(file_list) > 0:\n",
    "        print(f\"First file found: {file_list[0]}\")\n",
    "except NameError:\n",
    "    print(\"Error: SPECT_DIR variable is not defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150cf3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spectrogram Pre-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Videos:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Videos: 100%|██████████| 3/3 [00:35<00:00, 11.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SUCCESS ---\n",
      "Spectrograms saved to: D:/Downloads/audio/spec\n",
      "Spectrogram Pre-processing Complete.\n",
      "\n",
      "Starting Unsupervised Contrastive Training...\n",
      "DEBUG: Successfully found 270 spectrogram files.\n",
      "Loaded 270 spectrograms from D:/Downloads/audio/spec\n",
      "DEBUG: FINAL dataset size is 270\n",
      "Train samples: 189, Val samples: 54, Test samples: 27\n",
      "Visualizing features BEFORE training...\n",
      "Label counts: Counter({np.int64(0): 22, np.int64(2): 18, np.int64(1): 14})\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to interrupt the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.11.9' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # --- CRITICAL: FIX Dependency Error FIRST ---\n",
    "    # The 'bandpass_chunk' error means you must ensure the cells defining\n",
    "    # bandpass_chunk, spectral_subtract_quiet_frames, and clean_chunk \n",
    "    # are run successfully BEFORE this cell.\n",
    "    \n",
    "    # 1. RUN THE EXTRACTION ONCE TO CREATE .npy FILES\n",
    "    print(\"Starting Spectrogram Pre-processing...\")\n",
    "    prepare_dataset_from_videos(\n",
    "        raw_video_dir=RAW_VIDEOS,\n",
    "        audio_out_dir=AUDIO_DIR,\n",
    "        spect_out_dir=SPECT_DIR,\n",
    "        sr=SAMPLE_RATE,\n",
    "        chunk_seconds=CHUNK_SECONDS,\n",
    "        clean_chunk_func=clean_chunk # Pass the cleaning function you defined earlier\n",
    "    )\n",
    "    print(\"Spectrogram Pre-processing Complete.\")\n",
    "\n",
    "    # 2. START UNSUPERVISED TRAINING (This is the section that now uses the fixed code)\n",
    "    print(\"\\nStarting Unsupervised Contrastive Training...\")\n",
    "    model, test_loader, criterion = train_unsupervised()\n",
    "    \n",
    "    if model is None:\n",
    "        raise RuntimeError(\"Training failed or dataset was empty.\")\n",
    "      \n",
    "    # 3. EVALUATE AND VISUALIZE RESULTS\n",
    "    results = test_unsupervised(model, test_loader)\n",
    "    \n",
    "    # You will now get a plot saved to your directory and metrics printed out!\n",
    "    \n",
    "    # 4. SAVE FINAL MODEL\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    torch.save(model.state_dict(), os.path.join(\"models\", \"unsupervised_contrastive_audio_v1.pth\"))\n",
    "    print(\"Unsupervised pre-training complete and model saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
